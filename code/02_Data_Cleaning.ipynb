{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fdab76b",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2c01b",
   "metadata": {},
   "source": [
    "> In this notebook we will be cleaning these data to prepare it for EDA and Modeling. We will check for null values, outliers, errors, and other attributes that would depreciate EDA and Modeling. We will engineer features to get further insight into these data. We will be using functions such as `to_date`, `style_enumerator`, and `cleaned_data`. The process here serves the purpose for preparing the dataframe for future notebbooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a59938",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ded85",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21490573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import langid\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import googletrans\n",
    "import copy\n",
    "import urllib\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import re\n",
    "\n",
    "sa = SentimentIntensityAnalyzer()\n",
    "\n",
    "if sys.version_info < (3, 0):\n",
    "    from urllib2 import urlopen\n",
    "else:\n",
    "    from urllib.request import urlopen\n",
    "\n",
    "from googletrans import Translator\n",
    "from colorthief import ColorThief\n",
    "\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe7ab0c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751064b",
   "metadata": {},
   "source": [
    "## Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13408611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7c6aa",
   "metadata": {},
   "source": [
    "## Cleaning Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ccd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in Dataframe, returns numeric values for dates\n",
    "def to_date(dataframe):\n",
    "    \"\"\" to_date is a function that takes in the date data of the wikiart_scraped.csv and \n",
    "        replaces or converts the data to the correct corresponding integer.\n",
    "        \n",
    "        args: \n",
    "            dataframe : the intended dataframe of use is the wikiart_scraped.csv and was\n",
    "            designed around the dataset, it is returned with corrected dates\n",
    "    \n",
    "    \"\"\"\n",
    "    #This converts all roman numbers to century\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XIX-XX cent.'], value='1800')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XX cent.'],value='1900')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XVIII cent.'],value='1700')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XIX cent.'],value='1800')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XX-XXI cent.'],value='1900')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XVI-XVII cent.'],value='1500')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XV-XVI cent.'],value='1400')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XVII-XVIII cent.'],value='1600')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XVI cent.'],value='1500')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XV cent.'],value='1400')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XIV-XV cent.'],value='1300')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XVII cent.'],value='1600')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XII-XIII cent.'],value='1100')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['X cent.'],value='900')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XIII-XIV cent.'],value='1200')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['VIII cent.'],value='700')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['VII-VIII cent.'],value='600')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XIV cent.'],value='1300')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XI cent.'],value='1000')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XI-XII cent.'],value='1000')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XXI cent.'],value='2000')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XIX-XX cent.'],value='1800')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['XVIII-XIX cent.'],value='1800')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['47'], value='1447')\n",
    "    dataframe['Date'] = dataframe['Date'].replace(to_replace=['48'],value='1448')\n",
    "\n",
    "    ## Hyphen remover\n",
    "    for index, row in dataframe.iterrows():\n",
    "        date_range = row['Date']\n",
    "        for c in date_range:\n",
    "            if c == '-':\n",
    "                val = date_range[:date_range.index(c)]\n",
    "                dataframe.at[index, 'Date'] = (val)\n",
    "                break\n",
    "\n",
    "    #This converts all date's to numeric values\n",
    "    dataframe['Date'] = dataframe['Date'].astype(int)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee76c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_column(dataframe):\n",
    "    df['Language'] = None\n",
    "    for i in range(0, len(df['Artwork'])):\n",
    "        df['Language'][i] = langid.classify(dataframe['Artwork'][i])[0]    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b01eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_column(dataframe):\n",
    "    translator = Translator()\n",
    "    dataframe['Artwork'] = dataframe['Artwork'].astype(str)\n",
    "    dataframe['translated'] = dataframe.loc[dataframe.Language != 'en']['Artwork'].apply(translator.translate, \n",
    "                                                                                  src='auto', \n",
    "                                                                                  dest='en').apply(getattr, \n",
    "                                                                                                   args=('text',))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_data(dataframe):\n",
    "    \"\"\"\n",
    "    cleaned_data is a function that does blah blah blah and returns blah blah blah\n",
    "    \n",
    "    args: \n",
    "        dataframe: the dataframe that the user wants to clean\n",
    "    \"\"\"\n",
    "    print('Before Cleaning')\n",
    "    print('='*20)\n",
    "    print('Columns')\n",
    "    print(dataframe.columns)\n",
    "    print('_'*20)\n",
    "    print('Dataframe Size')\n",
    "    print(dataframe.shape)\n",
    "    print('_'*20)\n",
    "    print('Dataframe Unique Values')\n",
    "    print(dataframe.nunique())\n",
    "    print('_'*20)\n",
    "    print('Null Values in Each Column')\n",
    "    print(dataframe.isna().sum())\n",
    "    print('_'*20)\n",
    "    print('Data Types in Each Column')\n",
    "    print(dataframe.dtypes)\n",
    "    print('='*20)\n",
    "    \n",
    "    #This drops cuplicates of any work of art to decrease chances of sketches\n",
    "    dataframe = dataframe.drop_duplicates(subset=['Artwork', 'Artist', 'Date'], \n",
    "                       keep='last')\n",
    "    \n",
    "    #This drops any values in the style columns that have less than a count of 500\n",
    "    #So the model can properly train on the style\n",
    "    s = dataframe['Style'].value_counts() > 500\n",
    "    s = list(s[s == True].index)\n",
    "    dataframe = dataframe[dataframe['Style'].isin(s)]\n",
    "    \n",
    "    #Changing the dates to ints\n",
    "    dataframe = to_date(dataframe)\n",
    "    \n",
    "    #Adding a language column based on the language used in the Artwork column\n",
    "    dataframe = lang_column(dataframe)\n",
    "    \n",
    "    #Adding a translated title column based on Artwork column\n",
    "    dataframe = trans_column(dataframe)\n",
    "    \n",
    "    #Adding sentiment analysis column\n",
    "    dataframe['v_sent'] = dataframe.Artwork.apply(lambda r: sa.polarity_scores(r)['compound'])\n",
    "    \n",
    "    print('After Cleaning')\n",
    "    print('='*20)\n",
    "    print('Columns')\n",
    "    print(dataframe.columns)\n",
    "    print('_'*20)\n",
    "    print('Dataframe Size')\n",
    "    print(dataframe.shape)\n",
    "    print('_'*20)\n",
    "    print('Dataframe Unique Values')\n",
    "    print(dataframe.nunique())\n",
    "    print('_'*20)\n",
    "    print('Null Values in Each Column')\n",
    "    print(dataframe.isna().sum())\n",
    "    print('_'*20)\n",
    "    print('Data Types in Each Column')\n",
    "    print(dataframe.dtypes)\n",
    "    print('='*20)\n",
    "    \n",
    "    #returning the dataframe with an index reset\n",
    "    return dataframe.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cb01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = cleaned_data(df)\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e92485",
   "metadata": {},
   "source": [
    "# Creating Art Image Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1995adf7",
   "metadata": {},
   "source": [
    "> This for loop creates the list of folders based upon the styles within the `clean_df` to create the directory that will later be used for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fff31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../images/styles'\n",
    "list_styles = [i for i in clean_df['Style'].unique()]\n",
    "for items in list_styles:\n",
    "    path = os.path.join(root_path, items)\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b79f7",
   "metadata": {},
   "source": [
    "# Putting Images in Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519cd902",
   "metadata": {},
   "source": [
    "> The following for loop iterates through the `clean_df` dataframe, reads the image link, converts the image, resizes it, then saves it to it's corresponding `'Style` and index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d31d151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, row in clean_df.iterrows():\n",
    "\n",
    "    response = requests.get(clean_df['Link'][i])\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img = img.convert(\"RGB\") \n",
    "    img = img.resize((250,250))\n",
    "    filepath = f'../images/styles/{clean_df[\"Style\"][i]}/image_{i}.jpg'\n",
    "    img.save(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ae382",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ebad5b",
   "metadata": {},
   "source": [
    "## Grabbing dominant colors from filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa1548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import binascii\n",
    "import struct\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.cluster\n",
    "from scipy.spatial import KDTree\n",
    "from webcolors import CSS3_HEX_TO_NAMES, hex_to_rgb\n",
    "\n",
    "def dom_color(image):\n",
    "    # for loop that grabs each image\n",
    "    NUM_CLUSTERS = 5\n",
    "\n",
    "    # reading image\n",
    "    im = Image.open('../images/' + image, mode='r')\n",
    "    im = im.resize((150, 150))      # optional, to reduce time\n",
    "    ar = np.asarray(im)\n",
    "    shape = ar.shape\n",
    "    ar = ar.reshape(scipy.product(shape[:2]), shape[2]).astype(float)\n",
    "\n",
    "    # finding clusters\n",
    "    codes, dist = scipy.cluster.vq.kmeans(ar, NUM_CLUSTERS)\n",
    "    # print('Top 5 Colors:\\n', codes)\n",
    "\n",
    "    vecs, dist = scipy.cluster.vq.vq(ar, codes)         # assign codes\n",
    "    counts, bins = scipy.histogram(vecs, len(codes))    # count occurrences\n",
    "\n",
    "    index_max = scipy.argmax(counts)                    # find most frequent\n",
    "    peak = codes[index_max]\n",
    "    colour = binascii.hexlify(bytearray(int(c) for c in peak)).decode('ascii')\n",
    "    \n",
    "    # print('Most dominant color: %s (#%s)' % (peak, colour))\n",
    "    # print(colour)\n",
    "    \n",
    "    \n",
    "    peak = tuple(peak)\n",
    "    \n",
    "    # returns top color\n",
    "    def convert_rgb_to_names(peak):\n",
    "    \n",
    "        # a dictionary of all the hex and their respective names in css3\n",
    "        css3_db = CSS3_HEX_TO_NAMES\n",
    "        names = []\n",
    "        rgb_values = []\n",
    "        for color_hex, color_name in css3_db.items():\n",
    "            names.append(color_name)\n",
    "            rgb_values.append(hex_to_rgb(color_hex))\n",
    "    \n",
    "        kdt_db = KDTree(rgb_values)\n",
    "        distance, index = kdt_db.query(peak)\n",
    "        \n",
    "        top_color = names[index]\n",
    "        return top_color\n",
    "    \n",
    "    \n",
    "             \n",
    "    return colour, convert_rgb_to_names(peak)\n",
    "\n",
    "# source: https://medium.com/codex/rgb-to-color-names-in-python-the-robust-way-ec4a9d97a01f\n",
    "\n",
    "\n",
    "list_imgs = os.listdir('../images/')\n",
    "new_list_imgs = [\"../images/\" + f for f in list_imgs]\n",
    "\n",
    "# split up image folder into 20. \n",
    "chunks = [new_list_imgs[x:x+4500] for x in range(0, len(new_list_imgs), 4500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b239b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk0 = iter_colors(0)\n",
    "chunk1 = iter_colors(1)\n",
    "chunk2 = iter_colors(2)\n",
    "chunk3 = iter_colors(3)\n",
    "chunk4 = iter_colors(4)\n",
    "chunk5 = iter_colors(5)\n",
    "chunk6 = iter_colors(6)\n",
    "chunk7 = iter_colors(7)\n",
    "chunk8 = iter_colors(8)\n",
    "chunk9 = iter_colors(9)\n",
    "chunk10 = iter_colors(10)\n",
    "chunk11 = iter_colors(11)\n",
    "chunk12 = iter_colors(12)\n",
    "chunk13 = iter_colors(13)\n",
    "chunk14 = iter_colors(14)\n",
    "chunk15 = iter_colors(15)\n",
    "chunk16 = iter_colors(16)\n",
    "chunk17 = iter_colors(17)\n",
    "chunk18 = iter_colors(18)\n",
    "chunk19 = iter_colors(19)\n",
    "\n",
    "chunky_df = pd.concat([chunk0, \n",
    "                      chunk1,\n",
    "                      chunk2,\n",
    "                      chunk3,\n",
    "                      chunk4,\n",
    "                      chunk5,\n",
    "                      chunk6,\n",
    "                      chunk7,\n",
    "                      chunk8,\n",
    "                      chunk9,\n",
    "                      chunk10,\n",
    "                      chunk11,\n",
    "                      chunk12,\n",
    "                      chunk13,\n",
    "                      chunk14,\n",
    "                      chunk15,\n",
    "                      chunk16,\n",
    "                      chunk17,\n",
    "                       chunk18,\n",
    "                       chunk19])\n",
    "\n",
    "chunky_df = chunky_df.set_index('Image').sort_index().dropna()\n",
    "\n",
    "clean_df - clean_df.join(chunky_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['hex'] = None\n",
    "clean_df['color'] = None\n",
    "\n",
    "# iterate over files in that directory\n",
    "def iter_files(chunks):\n",
    "    for images in chunks:\n",
    "        print(images)\n",
    "        num = \"\"\n",
    "        for c in images:\n",
    "            if c.isdigit():\n",
    "                num = num + c\n",
    "        num = int(num)\n",
    "        # applies dominant color function\n",
    "        dom_color(images)    \n",
    "        # assigns dominant color hex to new column based on index\n",
    "        clean_df['hex'][num] = dom_color(images)[0]\n",
    "        clean_df['color'][num] = dom_color(images)[1]\n",
    "        print(dom_color(images))\n",
    "        print('---' *5)\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e4674",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba891a",
   "metadata": {},
   "source": [
    "## Saving the Cleaned Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc33b0a",
   "metadata": {},
   "source": [
    "> We save the data as `clean_art.csv` so that it may be used later for EDA for visualizations of the available data in `03_EDA.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('../data/clean_art.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
